---
title: 'Exercise set #2. MVA: Principal Component Analysis'
author: "Eudald Romo Grau y Laura Santulario Verdú"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

__1.__ Import the data file in the R environment using the read.table function. Make boxplots of these variables using the boxplot function. Make a scatterplot matrix of the nine body measurements. Comment your results. Compute the correlation
matrix and include it in your report.  

## Boxplot  

```{r echo = FALSE, message = FALSE, warning = FALSE}
datos <- read.table("BodyStudy.dat", header = TRUE)
datos <- as.matrix(datos)

# Boxplot
par(las = 2)
boxes <- boxplot(datos[ , 1:9],  ylab = "Measurements (cm)")
title("Boxplot")

Biacr.quant <- quantile(datos[ , 1], probs = c(0.25, 0.5, 0.75), names = FALSE)
Biili.quant <- quantile(datos[ , 2], probs = c(0.25, 0.5, 0.75), names = FALSE)
Bitro.quant <- quantile(datos[ , 3], probs = c(0.25, 0.5, 0.75), names = FALSE)
ChestDep.quant <- quantile(datos[ , 4], probs = c(0.25, 0.5, 0.75), names = FALSE)
ChestDia.quant <- quantile(datos[ , 5], probs = c(0.25, 0.5, 0.75), names = FALSE)
Elbow.quant <- quantile(datos[ , 6], probs = c(0.25, 0.5, 0.75), names = FALSE)
Wrist.quant <- quantile(datos[ , 7], probs = c(0.25, 0.5, 0.75), names = FALSE)
Knee.quant <- quantile(datos[ , 8], probs = c(0.25, 0.5, 0.75), names = FALSE)
Ankle.quant <- quantile(datos[ , 9], probs = c(0.25, 0.5, 0.75), names = FALSE)

quantile.matrix <- as.matrix(rbind(c(Biacr.quant[1] - 1.5 * (Biacr.quant[3] - Biacr.quant[1]), Biacr.quant, Biacr.quant[3] + 1.5 * (Biacr.quant[3] - Biacr.quant[1])),
c(Biili.quant[1] - 1.5 * (Biili.quant[3] - Biili.quant[1]), Biili.quant, Biili.quant[3] + 1.5 * (Biili.quant[3] - Biili.quant[1])),
c(Bitro.quant[1] - 1.5 * (Bitro.quant[3] - Bitro.quant[1]), Bitro.quant, Bitro.quant[3] + 1.5 * (Bitro.quant[3] - Bitro.quant[1])),
c(ChestDep.quant[1] - 1.5 * (ChestDep.quant[3] - ChestDep.quant[1]), ChestDep.quant, ChestDep.quant[3] + 1.5 * (ChestDep.quant[3] - ChestDep.quant[1])),
c(ChestDia.quant[1] - 1.5 * (ChestDia.quant[3] - ChestDia.quant[1]), ChestDia.quant, ChestDia.quant[3] + 1.5 * (ChestDia.quant[3] - ChestDia.quant[1])),
c(Elbow.quant[1] - 1.5 * (Elbow.quant[3] - Elbow.quant[1]), Elbow.quant, Elbow.quant[3] + 1.5 * (Elbow.quant[3] - Elbow.quant[1])), 
c(Wrist.quant[1] - 1.5 * (Wrist.quant[3] - Wrist.quant[1]), Wrist.quant, Wrist.quant[3] + 1.5 * (Wrist.quant[3] - Wrist.quant[1])),
c(Knee.quant[1] - 1.5 * (Knee.quant[3] - Knee.quant[1]), Knee.quant, Knee.quant[3] + 1.5 * (Knee.quant[3] - Knee.quant[1])),
c(Ankle.quant[1] - 1.5 * (Ankle.quant[3] - Ankle.quant[1]), Ankle.quant, Ankle.quant[3] + 1.5 * (Ankle.quant[3] - Ankle.quant[1]))), ncol = 5, nrow = 9)

Biacr.outliers <- which(datos[, 1] > quantile.matrix[1, 5] | datos[, 1] < quantile.matrix[1, 1])
Biili.outliers <- which(datos[, 2] > quantile.matrix[2, 5] | datos[, 2] < quantile.matrix[2, 1])
Bitro.outliers <- which(datos[, 3] > quantile.matrix[3, 5] | datos[, 3] < quantile.matrix[3, 1])
ChestDep.outliers <- which(datos[, 4] > quantile.matrix[4, 5] | datos[, 4] < quantile.matrix[4, 1])
ChestDia.outliers <- which(datos[, 5] > quantile.matrix[5, 5] | datos[, 5] < quantile.matrix[5, 1])
Elbow.outliers <- which(datos[, 6] > quantile.matrix[6, 5] | datos[, 6] < quantile.matrix[6, 1])
Wrist.outliers <- which(datos[, 7] > quantile.matrix[7, 5] | datos[, 7] < quantile.matrix[7, 1])
Knee.outliers <- which(datos[, 8] > quantile.matrix[8, 5] | datos[, 8] < quantile.matrix[8, 1])
Ankle.outliers <- which(datos[, 9] > quantile.matrix[9, 5] | datos[, 9] < quantile.matrix[9, 1])
```

From the boxplot it can be said that, for all variables,  there are no big differences (no many variability) of size among the women of this sample, because all boxes are short and also they are quite symmetric with not too long whiskers. 


## Scatterplot  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}
scatter <- pairs(datos[ , 1:9], lower.panel = NULL)
scatter
```


From the scatterplot it can be conclude that more or less all variables are essentially positive correlated among each other, but the correlation it is not so strong.  

## Correlation matrix  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}
corr.matrix <- cor(datos[ , 1:9])
corr.matrix
```


From the matrix above it is observed that all the correlations are positive and the pair of variables more correlated is Elbow - Wrist.  

__2.__ We do a PCA, using the covariance matrix. Compute a table with the decomposition of the variance obtained in PCA, reporting variances of components, percentages of explained variance, and cumulative percentages of explained variance. You can make use of R's function __princomp__ for this purpose. How many
components do you think you need to adequately describe this data set? Make a scree-plot of the eigenvalues to help you making your decision. Include all results and answers in your report.  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}
cov.matrix <- cov(datos[ , 1:9])

eigenvectors <- eigen(cov.matrix, symmetric = TRUE, only.values = FALSE)$vectors
centered.datos <- scale(datos[ , 1:9], scale = FALSE)
PCA <- centered.datos[ , 1:9]%*%eigenvectors

# Variances of components
comp.var <- eigen(cov.matrix, symmetric = TRUE, only.values = FALSE)$values
perc.var <- (comp.var/sum(comp.var))*100
cum.var <- (cumsum(comp.var)/sum(comp.var))*100
tabla.exp.var <- rbind(comp.var, perc.var, cum.var)

# Regarding percentage criteria (Pm > 80%) the number of principal components needed will be 3

# Regarding Kaiser criteria the number of principal components needed will be 5


#Screenplot
plot(comp.var, type = "b", xlab = "", ylab = "Component's Variance",
     main = paste("Representation of the Variance of all", "\nPrincipal Components"))
# Nos quedamos con dos componentes porque después de la segunda la variabilidad que se puede obtener de más no es muy significativa.  
```


__3.__ Make a PCA biplot of the previous analysis. You can make use of R's function __biplot__. However, it is usually possible to make nicer plots using the functions __plot__, __points__ and __arrows__. Take care to plot components that have not been standardized. Can you give an interpretation of the first and the second principal component?  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}
PCA.stand <- scale(PCA, center = TRUE, scale = TRUE)
head(PCA.stand, 5)


plot(PCA[ , 1], PCA[ , 2], xlab = "PC 1", ylab = "PC 2", 
     asp = 1, ylim = c(-7,7), main = "Biplot with covariance matrix")
abline(h = 0)
abline(v = 0)
text(PCA[ , 1], PCA[ , 2], 1:nrow(centered.datos), pos = 1)
arrows(0,0, 10*eigenvectors[,1], 10*eigenvectors[,2] , col = "blue")

# PC 1: The variables which has more wheited are 
# PC 2: The variables which has more wheited are Biacr, Biili, Bitro and ChestDia


```

__4.__  Extract the principal components computed by __princomp__ function by accessing the __scores__ object in the list object produced by __princomp__. Compute the correlations between the extracted principal components. Comment on your results.  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}

PCA.princomp <- princomp(datos[ , 1:9])$scores
head(PCA.princomp, 5)
round(cor(PCA.princomp), 2)
```

All principal components are uncorrelated  


__5.__  We now focus on the correlation structure of the variables, and do a second
principal component analysis using the correlation matrix. Extract the eigenvalues
and variance decomposition and report these in a Table. How much of the total
variance is accounted for by two principal components in this analysis?  

```{r echo = FALSE, memessage = FALSE, warning = FALSE}
cor.matrix <- cor(datos[ , 1:9])

cor.eigenvectors <- eigen(cor.matrix, symmetric = TRUE, only.values = FALSE)$vectors

cor.PCA <- centered.datos[ , 1:9]%*%cor.eigenvectors

# Variances of components
cor.comp.var <- eigen(cor.matrix, symmetric = TRUE, only.values = FALSE)$values
cor.perc.var <- (cor.comp.var/sum(cor.comp.var))*100
cor.cum.var <- (cumsum(cor.comp.var)/sum(cor.comp.var))*100
cor.tabla.exp.var <- rbind(cor.comp.var, cor.perc.var, cor.cum.var)

#Screenplot
plot(cor.comp.var, type = "b", xlab = "", ylab = "Component's Variance",
     main = paste("Representation of the Variance of all", "\nPrincipal Components"))

```

Two principal components represents only the 63.9% of the variability of the data.  

__6.__  Make a second biplot based on your last PCA and, use the standardized principal components in this plot. Add a unit circle to the biplot (you can use function draw.circle from package __plotrix__). Which variable has the poorest goodness-offit in this plot?  

```{r echo = FALSE, message = FALSE, warning = FALSE}
library(plotrix)
plot(cor.PCA[ , 1], cor.PCA[ , 2], xlab = "PC 1", ylab = "PC 2", 
     asp = 1,  main = "Biplot with correlation matrix")
abline(h = 0)
abline(v = 0)
text(PCA[ , 1], PCA[ , 2], 1:nrow(centered.datos), pos = 1)
arrows(0,0, cor.eigenvectors[,1], cor.eigenvectors[,2] , col = "blue")
draw.circle(cor.eigenvectors[,1], cor.eigenvectors[,2], 
            border = "blue")
```



__7.__  Compute the correlation matrix between the original variables and the first two principal components obtained by __princomp__. Which variables correlate highly with which components?  

```{r echo = FALSE, message = FALSE, warning = FALSE}
A <- round(cor(datos[ , 1:9], cbind(PCA.princomp[, 1], PCA.princomp[, 2])), 2)
colnames(A) <- c("PC1", "PC2")
A
```

Biili, Bitro, Knee with PC1
ChestDia with PC2


__8.__  Calculate the goodness-of-fit of the correlation matrix as it has been represented in the last biplot.  


__9.__  Study the relationships between the Age, Weight and Height, and the first two principal components by calculating correlations and making some plots. Do these variables help for interpreting the principal components?  



